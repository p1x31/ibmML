{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ml-latest.zip\n",
      "   creating: ml-latest/\n",
      "  inflating: ml-latest/links.csv     \n",
      "  inflating: ml-latest/tags.csv      \n",
      "  inflating: ml-latest/genome-tags.csv  \n",
      "  inflating: ml-latest/ratings.csv   \n",
      "  inflating: ml-latest/README.txt    \n",
      "  inflating: ml-latest/genome-scores.csv  \n",
      "  inflating: ml-latest/movies.csv    \n"
     ]
    }
   ],
   "source": [
    "!unzip ml-latest.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd\n",
    "from numpy import prod\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "\n",
    "from itertools import product\n",
    "from collections import namedtuple\n",
    "from collections import OrderedDict\n",
    "\n",
    "import warnings\n",
    "\"\"\"Optional[...] is a shorthand notation for Union[..., None], \n",
    "telling the type checker that either an object of the specific type is required, \n",
    "or None is required. ... stands for any valid type hint, \n",
    "including complex compound types or a Union[] of more types. \n",
    "Whenever you have a keyword argument with default value None, \n",
    "you should use Optional.\"\"\"\n",
    "from torch.jit.annotations import Optional, Tuple\n",
    "\n",
    "from torch.hub import load_state_dict_from_url\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device:', torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='./ml-latest/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>307</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>481</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1256677456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1091</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1256677471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1257</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1449</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1256677264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1      307     3.5  1256677221\n",
       "1       1      481     3.5  1256677456\n",
       "2       1     1091     1.5  1256677471\n",
       "3       1     1257     4.5  1256677460\n",
       "4       1     1449     4.5  1256677264"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv(path+'ratings.csv')\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title   \n",
       "0        1                    Toy Story (1995)  \\\n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv(path+'movies.csv')\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>110</th>\n",
       "      <th>260</th>\n",
       "      <th>296</th>\n",
       "      <th>318</th>\n",
       "      <th>356</th>\n",
       "      <th>480</th>\n",
       "      <th>527</th>\n",
       "      <th>589</th>\n",
       "      <th>593</th>\n",
       "      <th>1196</th>\n",
       "      <th>1198</th>\n",
       "      <th>1210</th>\n",
       "      <th>2571</th>\n",
       "      <th>2959</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48470</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63783</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77609</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94843</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111908</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117490</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123100</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134596</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141955</th>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158002</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172357</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183233</th>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212343</th>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242683</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253511</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId  1     110   260   296   318   356   480   527   589   593   1196   \n",
       "userId                                                                      \n",
       "48470     4.5   4.5   4.0   5.0   4.5   4.0   4.0   4.5   5.0   3.5   4.0  \\\n",
       "63783     5.0   1.0   5.0   5.0   5.0   4.0   4.0   5.0   4.0   5.0   5.0   \n",
       "77609     3.0   4.0   3.0   4.0   4.0   4.0   4.0   4.0   4.0   4.5   2.5   \n",
       "94843     1.0   2.5   2.5   3.5   2.5   3.0   1.0   0.5   NaN   3.0   2.5   \n",
       "111908    5.0   3.5   5.0   5.0   5.0   2.0   3.0   5.0   4.0   2.0   5.0   \n",
       "117490    4.0   5.0   4.0   4.5   4.0   4.0   3.0   4.0   4.0   4.0   4.0   \n",
       "123100    4.0   3.5   4.0   4.5   4.5   3.5   4.0   4.5   4.0   4.0   4.0   \n",
       "134596    3.0   4.0   4.0   4.0   4.5   3.0   4.0   4.0   4.0   4.0   4.0   \n",
       "141955    2.5   2.5   3.5   3.0   1.0   1.0   2.0   NaN   3.0   3.0   3.5   \n",
       "158002    5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   5.0   \n",
       "172357    4.0   4.0   3.0   5.0   5.0   2.0   2.5   3.5   5.0   4.0   5.0   \n",
       "183233    3.0   4.0   3.0   4.0   4.0   3.0   4.0   4.0   4.0   4.0   3.0   \n",
       "212343    3.5   4.0   0.5   5.0   5.0   3.5   3.0   4.5   3.5   5.0   0.5   \n",
       "242683    5.0   4.0   5.0   5.0   4.5   4.5   4.0   5.0   5.0   5.0   5.0   \n",
       "253511    4.0   4.0   4.0   4.5   4.0   3.5   4.0   4.0   4.0   4.5   4.0   \n",
       "\n",
       "movieId  1198  1210  2571  2959  \n",
       "userId                           \n",
       "48470     3.0   3.5   3.5   3.5  \n",
       "63783     4.0   5.0   5.0   5.0  \n",
       "77609     4.0   3.0   4.0   2.0  \n",
       "94843     2.5   1.0   3.0   2.5  \n",
       "111908    5.0   3.5   5.0   4.0  \n",
       "117490    4.0   4.0   4.0   3.0  \n",
       "123100    4.0   4.0   4.0   3.5  \n",
       "134596    4.5   4.0   4.5   4.0  \n",
       "141955    3.0   3.0   2.5   1.5  \n",
       "158002    5.0   4.0   5.0   5.0  \n",
       "172357    5.0   3.0   4.0   1.0  \n",
       "183233    4.0   3.0   5.0   4.0  \n",
       "212343    4.5   1.0   1.5   4.5  \n",
       "242683    5.0   4.0   5.0   4.0  \n",
       "253511    4.0   4.0   4.0   4.5  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = ratings.groupby('userId')['rating'].count()\n",
    "topUsers = g.sort_values(ascending=False)[:15]\n",
    "\n",
    "g=ratings.groupby('movieId')['rating'].count()\n",
    "topMovies=g.sort_values(ascending=False)[:15]\n",
    "\n",
    "top_r = ratings.join(topUsers, rsuffix='_r', how='inner', on='userId')\n",
    "top_r = top_r.join(topMovies, rsuffix='_r', how='inner', on='movieId')\n",
    "\n",
    "pd.crosstab(top_r.userId, top_r.movieId, top_r.rating, aggfunc=np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting fastai\n",
      "  Downloading fastai-2.7.12-py3-none-any.whl (233 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.1/233.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pip in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (23.1.2)\n",
      "Requirement already satisfied: packaging in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (21.3)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai)\n",
      "  Downloading fastdownload-0.0.7-py3-none-any.whl (12 kB)\n",
      "Collecting fastcore<1.6,>=1.5.29 (from fastai)\n",
      "  Downloading fastcore-1.5.29-py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torchvision>=0.8.2 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (0.13.1+cu116)\n",
      "Requirement already satisfied: matplotlib in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (3.5.3)\n",
      "Requirement already satisfied: pandas in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (2.0.1)\n",
      "Requirement already satisfied: requests in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (2.29.0)\n",
      "Requirement already satisfied: pyyaml in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (6.0)\n",
      "Collecting fastprogress>=0.2.4 (from fastai)\n",
      "  Downloading fastprogress-1.0.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: pillow>6.0.0 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (9.2.0)\n",
      "Requirement already satisfied: scikit-learn in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (1.2.2)\n",
      "Requirement already satisfied: scipy in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (1.9.0)\n",
      "Collecting spacy<4 (from fastai)\n",
      "  Downloading spacy-3.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch<2.1,>=1.7 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from fastai) (1.12.1+cu116)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4->fastai)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4->fastai)\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4->fastai)\n",
      "  Downloading murmurhash-1.0.9-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4->fastai)\n",
      "  Downloading cymem-2.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<4->fastai)\n",
      "  Downloading preshed-3.0.8-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting thinc<8.2.0,>=8.1.8 (from spacy<4->fastai)\n",
      "  Downloading thinc-8.1.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (924 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m924.9/924.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting wasabi<1.2.0,>=0.9.1 (from spacy<4->fastai)\n",
      "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4->fastai)\n",
      "  Downloading srsly-2.4.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (491 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.6/491.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting catalogue<2.1.0,>=2.0.6 (from spacy<4->fastai)\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0 (from spacy<4->fastai)\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting pathy>=0.10.0 (from spacy<4->fastai)\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting smart-open<7.0.0,>=5.2.1 (from spacy<4->fastai)\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from spacy<4->fastai) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from spacy<4->fastai) (1.20.3)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 (from spacy<4->fastai)\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from spacy<4->fastai) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from spacy<4->fastai) (67.7.2)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4->fastai)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from packaging->fastai) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from requests->fastai) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from requests->fastai) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from requests->fastai) (1.26.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from requests->fastai) (2022.12.7)\n",
      "Requirement already satisfied: typing-extensions in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from torch<2.1,>=1.7->fastai) (4.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from matplotlib->fastai) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from matplotlib->fastai) (4.36.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from matplotlib->fastai) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from pandas->fastai) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from pandas->fastai) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from scikit-learn->fastai) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from scikit-learn->fastai) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.2.0,>=8.1.8->spacy<4->fastai)\n",
      "  Downloading blis-0.7.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hCollecting confection<1.0.0,>=0.0.1 (from thinc<8.2.0,>=8.1.8->spacy<4->fastai)\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Collecting click<9.0.0,>=7.1.1 (from typer<0.8.0,>=0.3.0->spacy<4->fastai)\n",
      "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/vadim/anaconda3/envs/pytorch112/lib/python3.9/site-packages (from jinja2->spacy<4->fastai) (2.1.1)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, pydantic, murmurhash, langcodes, fastprogress, click, catalogue, blis, typer, srsly, preshed, fastcore, pathy, fastdownload, confection, thinc, spacy, fastai\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 click-8.1.3 confection-0.0.4 cymem-2.0.7 fastai-2.7.12 fastcore-1.5.29 fastdownload-0.0.7 fastprogress-1.0.3 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.7 smart-open-6.3.0 spacy-3.5.2 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.10 typer-0.7.0 wasabi-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c fastchan fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai.column_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfastai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlearner\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfastai\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolumn_data\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fastai.column_data'"
     ]
    }
   ],
   "source": [
    "from fastai.learner import *\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_cv_idxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_idxs \u001b[39m=\u001b[39m get_cv_idxs(\u001b[39mlen\u001b[39m(ratings))\n\u001b[1;32m      2\u001b[0m wd\u001b[39m=\u001b[39m\u001b[39m2e-4\u001b[39m\n\u001b[1;32m      3\u001b[0m n_factors \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_cv_idxs' is not defined"
     ]
    }
   ],
   "source": [
    "val_idxs = get_cv_idxs(len(ratings))\n",
    "wd=2e-4\n",
    "n_factors = 50\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = CollabFilterDataset.from_csv(path, 'ratings.csv', 'userId', 'movieId', 'rating')\n",
    "learn = cf.get_learner(n_factors, val_idxs, 64, opt_fn=optim.Adam, tmp_name=tmp_path, models_name=models_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(1e-2, 2, wds=wd, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = learn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=learn.data.val_y\n",
    "sns.jointplot(preds, y, kind='hex', stat_func=None);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_names = movies.set_index('movieId')['title'].to_dict()\n",
    "g=ratings.groupby('movieId')['rating'].count()\n",
    "topMovies=g.sort_values(ascending=False).index.values[:3000]\n",
    "topMovieIdx = np.array([cf.item2idx[o] for o in topMovies])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=learn.model; m.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_bias = to_np(m.ib(V(topMovieIdx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings = [(b[0], movie_names[i]) for i,b in zip(topMovies,movie_bias)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "movie_pca = pca.fit(movie_emb.T).components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = np.random.choice(len(topMovies), 50, replace=False)\n",
    "X = fac0[idxs]\n",
    "Y = fac1[idxs]\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.scatter(X, Y)\n",
    "for i, x, y in zip(topMovies[idxs], X, Y):\n",
    "    plt.text(x,y,movie_names[i], color=np.random.rand(3)*0.7, fontsize=11)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieEmbeddingModel(nn.Module):\n",
    "    def __init__(self, n_users, n_movies):\n",
    "        super().__init__()\n",
    "        self.movie_embeddings = nn.Embedding(n_movies, n_factors)\n",
    "        self.fc1 = nn.Linear(n_factors, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.movie_embeddings(x)\n",
    "        x = torch.mean(x, dim=1) # average embeddings\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-5\n",
    "model = MovieEmbeddingModel(n_users, n_movies).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-3, weight_decay=wd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch112",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
